[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nonlinear Methods Workshop Lecture Notes",
    "section": "",
    "text": "Preface\nOnline lecture notes for Nonlinear Methods Workshop held at Leuphana University in Lüneburg, 29 July – 2 August 2024.\nThere is also a PDF version of the lecture notes that can be downloaded.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction to recurrence plots",
    "section": "",
    "text": "1.1 A simple example\nWe start with the children’s rhyme by Helen H. Moore, shown below, to explore what recurrence in a time series is — exemplified here by the text, where each letter is a datum and time is represented by the position of the letter in the text.\nPop, pop, popcorn\nPopping in the pot!\nPop, pop, popcorn\nEat it while it's hot!\nPop, pop, popcorn\nButter on the top!\nWhen I eat popcorn\nI can't stop\nThe letters of the rhyme are encoded in the variable popcorn and we can the use the crqa() function from the package of the same name (Coco et al. 2021) to create the recurrence plot.\nThe first 30 elements of the popcorn vector are: P, O, P, ␣, P, O, P, ␣, P, O, P, C, O, R, N, ␣, P, O, P, P, I, N, G, ␣, I, N, ␣, T, H, E. Here the character “␣” represents a space between words. Line breaks and punctuation marks have been removed from the poem, and all letters are upper case, since we do not want to distinguish between lower case and upper case letters.\nThe R code shown below will compute and display the recurrence plot.\nlibrary(crqa)\n\nrp &lt;- crqa(popcorn, popcorn,\n           delay = 0,\n           embed = 0,\n           radius = 0.1,\n           method = \"rqa\",\n           datatype = \"categorical\")\n\nplot_rp(rp$RP)\n\n\n\n\nRecurrence plot of poem\nWe can also look at the first two verses of the poem, and put the letters on the axes, to make it a little easier to see how the underlying time series results in a recurrence plot.\nRecurrence plot of first two verses of the poem",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to recurrence plots</span>"
    ]
  },
  {
    "objectID": "intro.html#quantifying-the-recurrence-plot",
    "href": "intro.html#quantifying-the-recurrence-plot",
    "title": "1  Introduction to recurrence plots",
    "section": "1.2 Quantifying the recurrence plot",
    "text": "1.2 Quantifying the recurrence plot\nWith some training you can learn how to spot various properties of a time series simply by looking at the corresponding recurrence plot. In the case of the poem, we can see, for instance, that certain motifs are repeated in the poem. This is evident from the blue diagonal lines in the figure below, which correspond to the recurring motif “POP POP POPCORN”.\n\n\n\n\n\nRecurring motifs in the poem\n\n\n\n\nWhile we can gain some insights about the underlying time series from a visual inspection of the recurrence plot, we do not wish to rely on that. First, simply because we could overlook important features, and furthermore, it it not feasible for long time series or when comparing many time series. And, perhaps most importantly, we want objective measures, that do not depend on the skill of the person assessing the recurrence plot. With that said, it is still very useful to be able to visually inspect recurrence plots and infer something about the time series, so we definitely encourage you to work towards developing that skill as well.\nBut having objective quantitative measures that characterize features of a given recurrence plot is what has made recurrence plot analysis an effective tool, and that is why we will now look at recurrence quantification measures.\nSome of the most common recurrence quantification measures are reproduced in table Table 1.1, reproduced from Coco et al. (2021).\n\n\n\nTable 1.1: Common recurrence quantification measures\n\n\n\n\n\n\n\n\n\n\nMeasure\nAbbreviation\nDefinition\n\n\n\n\nRecurrence Rate\nRR\n\\(\\displaystyle \\frac{1}{N^2} \\sum_{i,j=1}^N R_{ij}\\)\n\n\nDeterminism\nDET\n\\(\\displaystyle \\left. \\sum_{l=l_\\mathrm{min}}^N lP(l) \\middle/ \\sum_{l=1}^N lP(l) \\right.\\)\n\n\nAverage Diagonal Line Length\nL\n\\(\\displaystyle \\left. \\sum_{l=l_\\mathrm{min}}^N lP(l) \\middle/ \\sum_{l=l_\\mathrm{min}}^N P(l) \\right.\\)\n\n\nMaximum Diagonal Line Length\nmaxL\n\\(\\displaystyle \\max(\\{l_i\\}_{i=1}^{N_l}), \\quad N_l = \\sum_{l\\geq l_\\mathrm{min}} P(l)\\)\n\n\nDiagonal Line Entropy\nENTR\n\\(\\displaystyle - \\sum_{l=l_\\mathrm{min}}^N p(l)\\log p(l)\\)\n\n\nLaminarity\nLAM\n\\(\\displaystyle \\left. \\sum_{v=v_\\mathrm{min}}^N vP(v) \\middle/ \\sum_{v=1}^N vP(v) \\right.\\)\n\n\nTrapping Time\nTT\n\\(\\displaystyle \\left. \\sum_{v=v_\\mathrm{min}}^N vP(v) \\middle/ \\sum_{v=v_\\mathrm{min}}^N P(v) \\right.\\)\n\n\nCategorical Area-based Entropy\ncatH\n\\(\\displaystyle - \\sum_{a&gt;1}^{N_a} p(a)\\log p(a)\\)\n\n\n\n\n\n\n\n\n\n\nCoco, Moreno I., Dan Mønster, Giuseppe Leonardi, Rick Dale, and Sebastian Wallot. 2021. “Unidimensional and Multidimensional Methods for Recurrence Quantification Analysis with Crqa.” The R Journal 13 (1): 145–63. https://doi.org/10.32614/RJ-2021-062.\n\n\nMarwan, Norbert, M. Carmen Romano, Marco Thiel, and Jürgen Kurths. 2007. “Recurrence Plots for the Analysis of Complex Systems.” Physics Reports 438 (56): 237–329. https://doi.org/10.1016/j.physrep.2006.11.001.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to recurrence plots</span>"
    ]
  },
  {
    "objectID": "rqa.html",
    "href": "rqa.html",
    "title": "2  Recurrence Quantification Analysis",
    "section": "",
    "text": "Under construction",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Recurrence Quantification Analysis</span>"
    ]
  },
  {
    "objectID": "crqa.html",
    "href": "crqa.html",
    "title": "3  Cross Recurrence Quantification Analysis",
    "section": "",
    "text": "Under construction",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cross Recurrence Quantification Analysis</span>"
    ]
  },
  {
    "objectID": "mdrqa.html",
    "href": "mdrqa.html",
    "title": "4  Multidimensional Recurrence Quantification Analysis",
    "section": "",
    "text": "Here you will find 6 exercises to learn different aspects of MdRQA and some questions to discuss. Copy the codes to RStudio, set the working directory to 06_MdRQA (setwd), and run the codes to look for the solutions. (Make sure you have ‘crqa’ and ‘ggplot2’ installed)\n\nPerforming MdRQA on the Lorenz system. How do the results differ from those found using RQA? For what reasons?\n\n\n# set path...\nsetwd(\"...\")\n\n# load package crqa\nlibrary(crqa)\nlibrary(ggplot2)\n\n# Run MdRQA on the 3d-Lorenz system\n\n# load data\nLorenz &lt;- read.csv(\"Lorenz.csv\")\n\n# run MdRQA\nres &lt;- crqa(ts1=Lorenz, ts2=Lorenz, delay=1, embed=1, radius=1.5,\n            normalize=0, tw=1, method=\"mdcrqa\")\n\n# check out recurrence measures\nhead(res)\n\n# plot RP\nRP &lt;- res$RP\nplot_rp(RP, xlabel = \"Time\", ylabel = \"Time\", geom = \"void\") + geom_point(size = 0.5)\n\n\nThe differences between a Theiler Window (tw) of 1 and 0.\nAdjust the code above to check.\nWhat measures were more affected by the change?\nWould you choose the same Theiler Window for CRQA?\nThe effects of noise on MdRQA outcomes.\nHow did the RP and the recurrence measures change?\nWhat could you do to receive more informative MdRQA outcomes?\n\n\n# load package crqa\nlibrary(crqa)\n\n# load data\nLorenz &lt;- read.csv(\"Lorenz.csv\")\n# load noisy data\nnoisy_Lorenz &lt;- read.csv(\"R.csv\")\n\n# add R to Lorenz data.frame\nLorenz$r &lt;- noisy_Lorenz$R\n\n# run MdRQA\nres &lt;- crqa(ts1=Lorenz, ts2=Lorenz, delay=1, embed=1, radius=1.5,\n            normalize=0, tw=1, method=\"mdcrqa\")\n\n# check out recurrence measures\nhead(res)\n\n# plot RP\nRP &lt;- res$RP\nplot_rp(RP, xlabel = \"Time\", ylabel = \"Time\", geom = \"void\") + geom_point(size = 0.5)\n\n\nThe effect of data normalization in MdRQA.\n\nLoad the file R.csv and add it to the Lorenz-data.frame as fourth variable. However, now use the scale() function to z-score the data from the R.csv-file before adding it as fourth variable to the Lorenz data frame.\nHow do the results change?\n\n# load package crqa\nlibrary(crqa)\n\n# load data\nLorenz &lt;- read.csv(\"Lorenz.csv\")\n# load noisy data\nnoisy_Lorenz &lt;- read.csv(\"R.csv\")\n\n# z-score R\nnoisy_Lorenz &lt;- scale(noisy_Lorenz$R)\n\n# add R to Lorenz data.frame\nLorenz$r &lt;- noisy_Lorenz\n\n# run MdRQA\nres &lt;- crqa(ts1=Lorenz, ts2=Lorenz, delay=1, embed=1, radius=1.5,\n            normalize=0, tw=1, method=\"mdcrqa\")\n\n# check out recurrence measures\nhead(res)\n\n# plot RP\nRP &lt;- res$RP\nplot_rp(RP, xlabel = \"Time\", ylabel = \"Time\", geom = \"void\") + geom_point(size = 0.5)\n\n\nRerun MdRQA on the Lorenz system with z-scored data (normalize = 2). Find a radius that yields %REC=5-10%.\n\n\n# load package crqa\nlibrary(crqa)\nlibrary(ggplot2)\n\n# Run MdRQA on the 3d-Lorenz system\n\n# load data\nLorenz &lt;- read.csv(\"Lorenz.csv\")\n\n# run MdRQA\nres &lt;- crqa(ts1=Lorenz, ts2=Lorenz, delay=1, embed=1, radius=1.2,\n            normalize=2, tw=1, method=\"mdcrqa\")\n\n# check out recurrence measures\nhead(res)\n\n# plot RP (it takes a minute here)\nRP &lt;- res$RP\nplot_rp(RP, xlabel = \"Time\", ylabel = \"Time\", geom = \"void\") + geom_point(size = 0.5)\n\n\nUse Lagged MdRQA to find the lags in the Lorenz system, inspect the Lorenz time series. Do the lags seem reasonable? Use the lagged MdRQA wrapper. Here we resample the Lorenz system for a quicker computation.\n\nFirst run the Lagged MdRQA function: (no need to dive in) Then use the next code for the task.\n\nlaggedMdrqa &lt;- function(maxlag, ts1, ts2, delay, embed, rescale,\n                        radius, normalize, mindiagline, minvertline, tw, method) {\n  # Note:\n  # This function wraps the crqa()-function from 'crqa' package.\n  # In order to run the function, the package 'crqa',\n  # as well its dependencies, need to be installed and loaded.\n  # The authors give no warranty for the correct functioning of \n  # the software and cannot be held legally accountable.\n\n# load libraries\nlibrary(crqa)\n\n# infer parameters to create empty matrix\nnoTs &lt;- dim(ts1)[2]\nlagList &lt;- matrix(0, ncol = noTs+1, nrow = (maxlag+1)^noTs)\n\n# compute list of lag combinations\nfor(i in 1:noTs) {\n    lagList[,i] &lt;-rep(0:maxlag, each = (maxlag+1)^(i-1), (maxlag+1)^(noTs-i))\n}\n\n# equate lags on lag0\nfor(i in 1:(maxlag+1)^noTs) {\n  lagList[i,1:noTs] &lt;- lagList[i,1:noTs]-min(lagList[i,1:noTs])\n}\n\n# compute lag identifier\nfor(i in 1:noTs) {\n  lagList[,noTs+1] &lt;- lagList[,noTs+1] + lagList[,i]*100^(noTs-i)\n}\n\n# discard all lags that are not unique\nlagList &lt;- subset(lagList, duplicated(lagList[,noTs+1]) == FALSE)\n\n# create results matrix and add lag parameters\nresults &lt;- matrix(nrow = dim(lagList)[1], ncol = (9+dim(lagList)[2]-1))\nresults[,10:(10+(dim(lagList)[2]-2))] &lt;- lagList[,1:(dim(lagList)[2]-1)]\n\n# run lagged mdrqa\nfor(i in 1:dim(lagList)[1]) {\n  \n  # create temporary data matrix\n  temp_ts1 &lt;- matrix(ncol = dim(ts1)[2], nrow = length((1+lagList[i,1]):(dim(ts1)[1]-maxlag+lagList[i,1])))\n  temp_ts2 &lt;- matrix(ncol = dim(ts2)[2], nrow = length((1+lagList[i,1]):(dim(ts2)[1]-maxlag+lagList[i,1])))\n  \n  # construct lagged time series\n  for(j in 1:dim(ts1)[2]) {\n    temp_ts1[,j] &lt;- ts1[(1+lagList[i,j]):(dim(ts1)[1]-maxlag+lagList[i,j]),j]\n  }\n  for(j in 1:dim(ts2)[2]) {\n    temp_ts2[,j] &lt;- ts2[(1+lagList[j,1]):(dim(ts2)[1]-maxlag+lagList[j,1]),j]\n  }\n  \n  # rund mdrqa\n        temp_res &lt;- crqa(ts1=temp_ts1, ts2=temp_ts2, delay = delay, embed = embed,\n                         rescale = rescale, radius = radius, normalize = normalize,\n                         mindiagline = mindiagline, minvertline = minvertline,\n                         tw = tw, method = \"mdcrqa\")\n        \n        # store recurrence measures on each iteration\n        results[i,1:9] &lt;- unlist(temp_res[1:9])\n} \n\n# convert results to data frame\nresults &lt;- as.data.frame(results)\n\n# generate and add labels\nnewLabels &lt;- c(\"RR\",\"DER\",\"NRLINE\",\"maxL\",\"L\",\"ENTR\",\"rENTR\",\"LAM\",\"TT\")\nj &lt;- 0\nfor(i in 10:(10+(dim(lagList)[2]-2))) {\n  j &lt;- j+1\n  newLabels[i] &lt;- paste(\"ts\",as.character(j),sep=\"\")\n}\ncolnames(results) &lt;- newLabels\n\n# sort data frame by RR\nresults &lt;- results[order(results$RR, decreasing = TRUE),]\n\n# return results\nreturn(results)\n}\n\nChoose some value for the „maxlag“ parameter between 10-30. Investigate the lag structure compared to the Lorenz system plot.\n\n# load packages\nlibrary(crqa)\nlibrary(ggplot2)\n\n#  Load Lorenz data\nLorenz &lt;- read.csv(\"Lorenz.csv\")\nLorenz$r &lt;- 1:nrow(Lorenz)\n\n# down-sample Lorenz data\ndown_Lorenz &lt;- Lorenz[seq(1,2500,by=10),]\n\n# plot down-sampled Lorenz data, dimension x\n\nggplot(down_Lorenz, aes(x = r)) +\n  geom_line(aes(y = x, color = \"x\")) +\n  geom_line(aes(y = y, color = \"y\")) +\n  geom_line(aes(y = z, color = \"z\")) +\n  labs(title = \"Down-Sampled Lorenz\") +\n  ylab('') + xlab('') +\n  theme_minimal() +\n  scale_color_manual(values = c(\"x\" = \"red\", \"y\" = \"green\", \"z\" = \"blue\"),\n                     name = \"Variables\") +\n  theme(legend.title = element_blank())\n\n\n# run lagged Mdrqa - chose a value for maxlag between 10 and 30\nres &lt;- laggedMdrqa(maxlag = ...,\n                   ts1 = down_Lorenz[,1:3],\n                   ts2 = down_Lorenz[,1:3],\n                   delay = 1,\n                   embed = 1,\n                   rescale = 0,\n                   radius = 0.5,\n                   normalize = 2,\n                   mindiagline = 2,\n                   minvertline = 2,\n                   tw = 1,\n                   method = \"mdcrqa\")\n\n# plot RR-function\nplot(res$RR, type = \"l\")\n\n# investigate the first couple of lags\nhead(res)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Multidimensional Recurrence Quantification Analysis</span>"
    ]
  },
  {
    "objectID": "parameter_estimation.html",
    "href": "parameter_estimation.html",
    "title": "5  Parameter Estimation for RQA",
    "section": "",
    "text": "Under construction",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Parameter Estimation for RQA</span>"
    ]
  },
  {
    "objectID": "parameter_sensitivity.html",
    "href": "parameter_sensitivity.html",
    "title": "6  Parameter Sensitivity Analysis for RQA",
    "section": "",
    "text": "Assuming we are dealing with continuous time series rather than categorical time series, we estimate embedding parameters (delay and embedding dimension) as well as an appropriate radius parameter used to construct recurrence plots.\n\n# You may need to set the path here\nsetwd(\"\")\n\n# load packages\nlibrary(crqa)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Load data files\n# You may need to change the path, depending on your working directory and where you have the file.\nload(\"../07_sample_analyses/dataSampleAnalysis_new.Rdata\")\n\n# Set the experimental condition\n# (o)ral reading = 0, (s)ilent reading = 1\nCON &lt;- factor(c(rep(0,6),rep(1,6))) \n\n# Enter the estimated parameters from the previous exercise\nopt_delay &lt;-  1\nopt_embed &lt;-  4\nopt_radius &lt;-  0.65\n\n# Now assign the part of parameter space to be explored\ndelay_values &lt;- seq(1, ...) # Set values here\nembed_values &lt;-             # Set values here\nradius_values &lt;-            # Set values here\n  \n# Start with an empty data frame for the RQA results and parameters\nexploration &lt;- data.frame()\n\nfor (d in delay_values) {\n  for (e in embed_values) {\n    for (r in radius_values) {\n      for(i in 1:12) {\n        # Note: we exclude the last data point\n        temp &lt;- crqa(ts1 = data[1:1098, i],\n                     ts2 = data[1:1098, i],\n                     rescale = 0,\n                     delay = d,\n                     embed = e,\n                     radius = r,\n                     normalize = 2,\n                     tw = 1,\n                     method = \"rqa\")\n        result &lt;- data.frame(\n          REC = temp$RR,\n          CON = CON[i],\n          delay = d,\n          embed = e,\n          radius = r\n        )\n        exploration &lt;- bind_rows(exploration, result)\n      }\n    }\n  }\n}\n\n# Compute exp_test which holds the results of the t-test for each set of\n# parameters.\nexp_test &lt;- data.frame()\n\nfor (d in delay_values) {\n  for (e in embed_values) {\n    for (r in radius_values) {\n      # Add t-test here\n      TT &lt;- t.test(REC ~ CON, \n                   data = exploration |&gt;\n                     filter(delay == d, embed == e, radius == r))\n      exp_test &lt;- bind_rows(\n        exp_test,\n        data.frame(\n          delay = d,\n          embed = e,\n          radius = r,\n          p_value = TT$p.value,\n          difference = TT$estimate[1] - TT$estimate[2],\n          CI_lo = TT$conf.int[1],\n          CI_hi = TT$conf.int[2]\n        )\n      )\n    }\n  }\n}\n\n# Add a variable for whether the t-test is significant\nexp_test &lt;- exp_test |&gt;\n  mutate(significant = (p_value &lt; 0.05))\n\n\n# Plot the result for the optimal parameters\nggplot(exploration |&gt; \n         filter(delay == opt_delay, \n                embed == opt_embed,\n                radius == opt_radius),\n       aes(x = CON, y = REC)) +\n  geom_boxplot() +\n  geom_point(aes(y = REC), position = position_jitter()) +\n  labs(title = \"Difference in conditions with chosen parameters\") +\n  theme_classic()\n\n\n\n# Same plot but as a violin plot\nggplot(exploration |&gt; \n         filter(delay == opt_delay, \n                embed == opt_embed,\n                radius == opt_radius),\n       aes(x = CON, y = REC)) +\n  geom_violin() +\n  geom_point(aes(y = REC), position = position_jitter()) +\n  labs(title = \"Difference in conditions with chosen parameters\") +\n  theme_classic()\n\n\n# Look at result of t-test for different values of embedding dimension\nggplot(exp_test |&gt; \n         filter(delay == opt_delay, radius == opt_radius),\n       aes(x = embed, y = p_value)) +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n  geom_line() +\n  geom_point(data = exp_test |&gt; \n               filter(embed == opt_embed,\n                      radius == opt_radius,\n                      delay == opt_delay),\n             size = 4, colour = \"blue\") +\n  xlab(\"Embedding dimension\") +\n  ylab(\"p-value\") +\n  theme_bw()\n\n\nggplot(exp_test |&gt; \n         filter(delay == opt_delay, radius == opt_radius),\n       aes(x = embed, y = difference)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_errorbar(aes(ymin = CI_lo, ymax = CI_hi)) +\n  geom_point() +\n  geom_point(data = exp_test |&gt; \n               filter(embed == opt_embed,\n                      radius == opt_radius,\n                      delay == opt_delay),\n             aes(y = difference),\n             size = 4, colour = \"blue\") +\n  xlab(\"Embedding dimension\") +\n  ylab(\"95% CI\") +\n  theme_bw()\n\n\n\n# Look at result of t-test for different values of delay\nggplot(exp_test |&gt; \n         filter(embed == opt_embed, radius == opt_radius),\n       aes(x = delay, y = p_value)) +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n  geom_line() +\n  geom_point(data = exp_test |&gt; \n               filter(embed == opt_embed,\n                      radius == opt_radius,\n                      delay == opt_delay),\n             size = 4, colour = \"blue\") +\n  xlab(\"Delay\") +\n  ylab(\"p-value\") +\n  theme_bw()\n\n\nggplot(exp_test |&gt; \n         filter(embed == opt_embed, radius == opt_radius),\n       aes(x = delay, y = difference)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_errorbar(aes(ymin = CI_lo, ymax = CI_hi)) +\n  geom_point() +\n  geom_point(data = exp_test |&gt; \n               filter(embed == opt_embed,\n                      radius == opt_radius,\n                      delay == opt_delay),\n             aes(y = difference),\n             size = 4, colour = \"blue\") +\n  xlab(\"Delay\") +\n  ylab(\"95% CI\") +\n  theme_bw()\n\n\n\n# Look at result of t-test for different values of radius\nggplot(exp_test |&gt; \n         filter(embed == opt_embed, delay == opt_delay),\n       aes(x = radius, y = p_value)) +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n  geom_line() +\n  geom_point(data = exp_test |&gt; \n               filter(embed == opt_embed,\n                      radius == opt_radius,\n                      delay == opt_delay),\n             size = 4, colour = \"blue\") +\n  xlab(\"Radius\") +\n  ylab(\"p-value\") +\n  theme_bw()\n\n\nggplot(exp_test |&gt; \n         filter(embed == opt_embed, delay == opt_delay),\n       aes(x = radius, y = difference)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_errorbar(aes(ymin = CI_lo, ymax = CI_hi)) +\n  geom_point() +\n  geom_point(data = exp_test |&gt; \n               filter(embed == opt_embed,\n                      radius == opt_radius,\n                      delay == opt_delay),\n             aes(y = difference),\n             size = 4, colour = \"blue\") +\n  xlab(\"Radius\") +\n  ylab(\"95% CI\") +\n  theme_bw()\n\n\n#\n# Keep radius fixed. Vary the other parameters.\n#\nggplot(exploration |&gt; filter(radius == opt_radius),\n       aes(x = CON, y = REC)) +\n  geom_rect(data = exp_test |&gt; filter(radius == opt_radius),\n            aes(fill = significant), inherit.aes = FALSE,\n            xmin = -Inf, xmax = Inf,\n            ymin = -Inf, ymax = Inf, alpha = 0.3) +\n  geom_rect(data = exp_test |&gt;\n              filter(embed == opt_embed,\n                     radius == opt_radius,\n                     delay == opt_delay),\n            colour = \"blue\", \n            linewidth = 1.5,\n            fill = NA,\n            inherit.aes = FALSE,\n            xmin = -Inf, xmax = Inf,\n            ymin = -Inf, ymax = Inf, alpha = 0.3) +\n  geom_violin() +\n  geom_point(position = position_jitter(),\n             size = 1, shape = \"o\") +\n  theme_classic() +\n  facet_grid(delay ~ embed) +\n  theme(legend.position = \"top\")\n\n\n# Same but with radius as facet instead of delay\nggplot(exploration |&gt; filter(delay == opt_delay),\n       aes(x = CON, y = REC)) +\n  geom_rect(data = exp_test |&gt; filter(delay == opt_delay),\n            aes(fill = significant), inherit.aes = FALSE,\n            xmin = -Inf, xmax = Inf,\n            ymin = -Inf, ymax = Inf, alpha = 0.3) +\n  geom_rect(data = exp_test |&gt;\n              filter(embed == opt_embed,\n                     radius == opt_radius,\n                     delay == opt_delay),\n            colour = \"blue\", \n            linewidth = 1.5,\n            fill = NA,\n            inherit.aes = FALSE,\n            xmin = -Inf, xmax = Inf,\n            ymin = -Inf, ymax = Inf, alpha = 0.3) +\n  # geom_boxplot() +\n  geom_violin() +\n  geom_point(position = position_jitter(),\n             size = 1, shape = \"o\") +\n  theme_classic() +\n  facet_grid(radius ~ embed) +\n  theme(legend.position = \"top\")\n\n\n\n# Same but with embedding fixed\nggplot(exploration |&gt; filter(embed == opt_embed),\n       aes(x = CON, y = REC)) +\n  geom_rect(data = exp_test |&gt; filter(embed == opt_embed),\n            aes(fill = significant), inherit.aes = FALSE,\n            xmin = -Inf, xmax = Inf,\n            ymin = -Inf, ymax = Inf, alpha = 0.3) +\n  geom_rect(data = exp_test |&gt;\n              filter(embed == opt_embed,\n                     radius == opt_radius,\n                     delay == opt_delay),\n            colour = \"blue\", \n            linewidth = 1.5,\n            fill = NA,\n            inherit.aes = FALSE,\n            xmin = -Inf, xmax = Inf,\n            ymin = -Inf, ymax = Inf, alpha = 0.3) +\n  # geom_boxplot() +\n  geom_violin() +\n  geom_point(position = position_jitter(),\n             size = 1, shape = \"o\") +\n  theme_classic() +\n  facet_grid(delay ~ radius) +\n  theme(legend.position = \"top\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Parameter Sensitivity Analysis for RQA</span>"
    ]
  },
  {
    "objectID": "fractal_analysis.html",
    "href": "fractal_analysis.html",
    "title": "7  Fractal Analysis",
    "section": "",
    "text": "Under construction",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Fractal Analysis</span>"
    ]
  },
  {
    "objectID": "ccm.html",
    "href": "ccm.html",
    "title": "8  Convergent Cross Mapping",
    "section": "",
    "text": "8.1 The logistic map\nThe logistic map is defined by the difference equation \\[\n  X_{n+1} = r X_n (1 - X_{n})\n\\]\nLet us start by generating a time series for a particular start value of \\(X\\) and a particular value of the growth parameter \\(r\\). This is done by calling the function logistic_map() which is defined below.\nlibrary(ggplot2)\nlibrary(dplyr)\n\nlogistic_map &lt;- function(x0 = 0.2,\n                         r = 3.65,\n                         N = 100,\n                         N_skip = 0) {\n  X &lt;- rep(0, N)\n  if (N_skip &gt; 0) {\n    #\n    # Iterate for N_trans generations without collecting data (only\n    # X[1] is updated, so the last data point will be\n    # used as the new X[1]).\n    #\n    X0 &lt;- x0\n    for (t in 1:N_skip) {\n      X[1] &lt;-  X0 * (r - r * X0)\n      X0 &lt;-  X[1]\n    }\n  } else {\n    X0 &lt;- x0\n    X[1] &lt;-  X0 * (r - r * X0)\n  }\n  \n  # Iterate the coupled maps for N generations\n  for (t in 2:N) {\n    X[t] &lt;-  r * X[t - 1] * (1 - X[t - 1])\n  }\n  \n  return(\n    data.frame(\n      time = 1:N,\n      X = X\n    )\n  )\n}\nWe can call this function with an initial value \\(X_0\\) and some value for the growth parameter or control parameter. If we do not set the number of points to generate and the number of points to skip (the transient phase) these parameters will have the default values defined in the function above.\ntime_series &lt;- logistic_map(x0 = 0.3, r = 3.2)\n\nggplot(time_series,\n       aes(x = time, y = X)) +\n  geom_line() +\n  theme_classic()\nHere, we see that the system is periodic with period 2, after a short initial period of transient behaviour.\nWe can choose a different value for the growth (control) parameter, \\(r\\).\ntime_series &lt;- logistic_map(x0 = 0.3, r = 3.65)\n\nggplot(time_series,\n       aes(x = time, y = X)) +\n  geom_line() +\n  theme_classic()\nLet us try to construct the bifurcation diagram, i.e., a plot of the asymptotic states as a function of the growth rate, \\(r\\).\nThe function get_stable_points() collects a number, N_plot, points that are approximations to the asymptotic values. The first 200 points are skipped, and then N_plot points are saved. The minimum (r_min) and maximum, r_max, \\(r\\)-values can be set, as well as the number of \\(r\\)-values to sample in the interval [r_min, r_max].\nget_stable_points &lt;- function(r_min = 2.75,\n                              r_max = 4,\n                              r_steps = 1200,\n                              N_plot = 100) {\n  #  number(N_r)  and step size (dr) in r\n  dr &lt;- (r_max - r_min) / r_steps\n  \n  stable_points &lt;- data.frame()\n  \n  r_values &lt;- seq(r_min, r_max, by = dr)\n  for (r in r_values) {\n    time_series &lt;- logistic_map(x0 = 0.2, r = r, N = N_plot, N_skip = 200)\n    stable_points &lt;- bind_rows(\n      stable_points,\n      data.frame(r = rep(r, N_plot),\n                 X = time_series$X)\n    )\n  }\n  return(stable_points)\n}\nNow we can use this function to generate the stable points and plot them. This may take a while, but should not take several minutes.\nstable_points &lt;- get_stable_points(r_steps = 2500, N_plot = 200)\n\n# Retrieve the step size in r\nr_values &lt;- sort(unique(stable_points$r))\ndr &lt;- r_values[2] - r_values[1]\n\nggplot(stable_points,\n       aes(x = r, y = X)) +\n  geom_tile(width = dr, height = dr) +\n  theme_classic()\nLet us zoom in on the interval from \\(r = 3.8\\) to \\(r = 3.9\\). To do this, we generate a new set of stable points in this interval of \\(r\\) values, so a little patience is required again.\nstable_points &lt;- get_stable_points(r_min = 3.8,\n                                   r_max = 3.9,\n                                   r_steps = 2500,\n                                   N_plot = 200)\n\n# Retrieve the step size in r to set the size of tiles in plot\nr_values &lt;- sort(unique(stable_points$r))\ndr &lt;- r_values[2] - r_values[1]\n\nggplot(stable_points,\n       aes(x = r, y = X)) +\n  # geom_point(size = 0.1, stroke = 0, shape = \".\") +\n  # Smallest points are too large, so we use tiles instead\n  geom_tile(width = dr, height = 10 * dr, fill = \"black\") +\n  theme_classic()\nHere we see periodic behaviour with a period of three emerge around \\(r \\approx 3.83\\) after being in a chaotic regime.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Convergent Cross Mapping</span>"
    ]
  },
  {
    "objectID": "ccm.html#the-logistic-map",
    "href": "ccm.html#the-logistic-map",
    "title": "8  Convergent Cross Mapping",
    "section": "",
    "text": "Question\n\n\n\nCan you see examples of self-similarity?\n\n\n\n8.1.1 NLM logo\nIf we want to reproduce the workshop logo, we have to change colors and remove axes, etc.\n\nstable_points &lt;- get_stable_points(r_min = \"Set value here\",\n                                   r_max = \"set value here\",\n                                   r_steps = \"Set value here\",\n                                   N_plot = \"Set value here\")\n\n# Retrieve the step size in r to set the size of tiles in plot\nr_values &lt;- sort(unique(stable_points$r))\ndr &lt;- r_values[2] - r_values[1]\n\nbg_colour &lt;- \"#2D6660\"\nfg_colour &lt;- \"white\"\n\nggplot(stable_points |&gt; \n         filter(X &gt; \"Set value here\"),\n       aes(x = r, y = X)) +\n  geom_tile(width = dr, height = dr, fill = fg_colour) +\n  theme_void() +\n  theme(plot.background = element_rect(fill = bg_colour, colour = bg_colour))\n\n# You can save the plot with this command\nggsave(\"NLM_logo.png\", width = 10, height = 4)\n\nIf you set the right values, you should get something similar to the plot below.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Convergent Cross Mapping</span>"
    ]
  },
  {
    "objectID": "ccm.html#model-example-the-coupled-logistic-map",
    "href": "ccm.html#model-example-the-coupled-logistic-map",
    "title": "8  Convergent Cross Mapping",
    "section": "8.2 Model example: The coupled logistic map",
    "text": "8.2 Model example: The coupled logistic map\nA simple example of a nonlinear system with two variables is the coupled logistic map. The two variables \\(X\\) and \\(Y\\) have internal dynamics depending on the growth rates \\(r_X\\) and \\(r_Y\\). In addition there is interdependent dynamics modeled as a causal effect of \\(X\\) on \\(Y\\) depending on the coupling constant \\(\\beta_{YX}\\) and a coupling in the inverse direction depending on \\(\\beta_{XY}\\).\nThe model is expressed by these two equations: \\[\n  X_{n+1} = X_n ( r_X - r_X X_{n} - \\beta_{XY}Y_n)\n\\]\n\\[\n  Y_{n+1} = Y_n ( r_Y - r_Y Y_{n} - \\beta_{YX}X_n)\n\\]\nAs for the simple logistic map, we will use a function to generate values by iterating the equations above that define the coupled logistic map.\n\ncoupled_logistic_map &lt;- function(x0 = 0.2,\n                                 y0 = 0.6,\n                                 rx = 3.65,\n                                 ry = 3.8,\n                                 bxy = 0,\n                                 byx = 0.4,\n                                 N = 100,\n                                 N_skip = 0) {\n  X &lt;- rep(0, N)\n  Y &lt;- rep(0, N)\n  if (N_skip &gt; 0) {\n    #\n    # Iterate for N_trans generations without collecting data (only\n    # X[1] and Y[1] are updated, so the last data point will be\n    # used as the new X[1] and Y[1]).\n    #\n    X0 &lt;- x0\n    Y0 &lt;- y0\n    for (t in 1:N_skip) {\n      X[1] &lt;-  X0 * (rx - rx * X0 - bxy * Y0)\n      Y[1] &lt;-  Y0 * (ry - ry * Y0 - byx * X0)\n      X0 &lt;-  X[1]\n      Y0 &lt;-  Y[1]\n    }\n  } else {\n    X0 &lt;- x0\n    Y0 &lt;- y0\n    X[1] &lt;-  X0 * (rx - rx * X0 - bxy * Y0)\n    Y[1] &lt;-  Y0 * (ry - ry * Y0 - byx * X0)\n  }\n  \n  # Iterate the coupled maps for N generations\n  for (t in 2:N) {\n    X[t] &lt;-  X[t - 1] * (rx - rx * X[t - 1] - bxy * Y[t - 1])\n    Y[t] &lt;-  Y[t - 1] * (ry - ry * Y[t - 1] - byx * X[t - 1])\n  }\n  \n  return(\n    data.frame(\n      time = 1:N,\n      X = X,\n      Y = Y\n    )\n  )\n}\n\n\n8.2.1 Time series (hands on exercise 1)\nThe model is implemented in the function coupled_logistic_map which can generate time series of length N given initial values x0and y0 of the two variables and values for all the parameters in the model. To avoid transient and possible idiosyncratic dynamics in the beginning, an optional parameter N_skip can be set that will skip the first N_skip data points and then run the model for an additional N generations.\n\n# Note the parameters here are not the exact ones used in the slides\ntime_series &lt;- coupled_logistic_map(\n  x0 = 0.2,\n  y0 = 0.6,\n  rx = 3.65,\n  ry = 3.8,\n  bxy = 0,\n  byx = 0.4,\n  N = 1000,\n  N_skip = 300\n)\n\nHere are plots of the first 40 values of \\(X\\) and \\(Y\\).\n\n\n\n\n\n\nNote\n\n\n\nThese plots are slightly different from those in the slides, because the parameters are not exactly the same.\n\n\n\nlibrary(ggplot2)\n\nggplot(time_series, aes(x = time, y = X)) +\n  geom_point(colour = \"blue\") +\n  geom_line(colour = \"blue\") +\n  xlim(c(1, 40)) +\n  ylab(\"Population X\") +\n  theme_classic()\n\n\n\n\n\n\n\nggplot(time_series, aes(x = time, y = Y)) +\n  geom_point(colour = \"red\") +\n  geom_line(colour = \"red\") +\n  xlim(c(1, 40)) +\n  ylab(\"Population Y\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n8.2.2 Attractor reconstruction\nReconstruct attractors from \\(X\\) and \\(Y\\). Here you need to set the embedding dimension.\n\nlibrary(tseriesChaos)\nlibrary(dplyr)\n\n# Construct attractors using tseriesChaos::embedd()\n# Note: I use a negative sign for delay to match the plot in the slides.\n# What happens if you have a positive sign instead?\n\n# Set the embedding dimension here. What should it be?\ndimension &lt;- NA\ndelay &lt;- 1\n\nMX &lt;- embedd(time_series$X, m = dimension, d = -delay)\nMY &lt;- embedd(time_series$Y, m = dimension, d = -delay)\n\n# Change the column names\ncolnames(MX) &lt;- c(\"t\", \"t_minus_delay\")\ncolnames(MY) &lt;- c(\"t\", \"t_minus_delay\")\n\nWe can then add a variable name and bind the two time series into a data frame, so that we can plot the result.\n\nattractors &lt;- rbind(\n  as.data.frame(MX) |&gt; mutate(variable = \"X\"),\n  as.data.frame(MY) |&gt; mutate(variable = \"Y\")\n)\n\nggplot(attractors, aes(x = t, y = t_minus_delay, colour = variable)) +\n  geom_point() +\n  scale_color_manual(values = c(\"X\" = \"blue\", \"Y\" = \"red\")) +\n  xlab(\"Value at time t\") +\n  ylab(\"Value at time t-1\") +\n  coord_fixed() +\n  theme_classic()\n\nYou should get something similar to the plots below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat did you discover?\n\n\n\nWhat was the correct embedding dimension?\nWhat happens if \\(\\beta_{XY} &gt; 0\\)?\n\n\n\n\n8.2.3 Convergent cross mapping (hands-on exercise 2)\nUse the CCM()function to calculate cross map skill.\n\n\n\n\n\n\nNote\n\n\n\nThis function takes a while to run. If you wish to experiment, use a smaller library size, and/or smaller sample. To decrease noise, increase the sample size.\n\n\n\nlibrary(rEDM)\n# Perform the cross mapping. This can take some time.\n\n#\n# Exercise: supply the libSizes argument to the CCM() function\n#\n\n# Hint: it has the form \"min max step\", can be generated like this:\nlib_min &lt;- NA # Insert value of minimum library size here\nlib_max &lt;- NA # Insert value of maximum library size here\nlib_step &lt;- NA # Insert value of step here. Not too small!\nlib_sizes &lt;- paste(lib_min, lib_max, lib_step)\n\nmodel_ccm &lt;- CCM(dataFrame = time_series,\n                 E = dimension, tau = -delay, Tp = 0,\n                 columns = \"Y\", target = \"X\",\n                 libSizes = lib_sizes, sample = 20,\n                 showPlot = TRUE)\n\n# Make sure the data frame has valid names (no colons)\ncolnames(model_ccm) &lt;- make.names(colnames(model_ccm))\n\nSince the CCM() function returns that data, we can also make our own plot.\n\nlibrary(tidyr)\nlibrary(latex2exp)\n\n# Construct a long form version of the data\nmodel_ccm_long &lt;- model_ccm |&gt; \n  rename(Y.MX = X.Y, X.MY = Y.X, L = LibSize) %&gt;% \n  pivot_longer(cols = c(\"Y.MX\", \"X.MY\"),\n               names_to = \"Crossmap\",\n               values_to = \"Rho\")\n\nggplot(model_ccm_long, aes(x = L, y = Rho, color = Crossmap)) +\n  geom_point(size = 1) +\n  geom_line() +\n  scale_color_manual(values = c(\"X.MY\" = \"blue\", \"Y.MX\" = \"red\"),\n                     aesthetics = c(\"colour\", \"fill\"),\n                     breaks = c(\"X.MY\", \"Y.MX\"),\n                     labels =  c(\"Y xmap X\", \"X xmap Y\")) +\n  ylab(TeX(\"$\\\\rho$\")) +\n  theme_classic() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat did you discover?\n\n\n\nWhat an you conclude based on the plot?\nDescribe your observations and reasoning.\n\n\n\n\n8.2.4 Fitting the convergence (hands-on exercise 3)\nThe first step is to fit the cross-mapping data to the function using nonlinear least squares regression. Unlike lineaer regression, there is no closed-form solution, so the regression equations are solved using a numerical iterative approach that is not guaranteed to converge on a solution.\nYou may therefore need to provide an initial guess that is not too far from the least squares solution.\n\nccm_fit_X &lt;- nls(Rho ~ a * exp(-g * L) + r,\n               data = model_ccm_long |&gt; filter(Crossmap == \"X.MY\"),\n               start = list(a = -0.5, g = 0.05, r = 0))\n\n# summary(ccm_fit_X)\n\n# Note: this model might not converge.\n# If it fails, you can comment this out.\nccm_fit_Y &lt;- nls(Rho ~ a * exp(-g * L) + r,\n               data = model_ccm_long |&gt;  filter(Crossmap == \"Y.MX\"),\n               start = list(a = -0.1, g = 0.05, r = 0))\n\n# summary(ccm_fit_Y)\n\n\n# Extract the predictions. If a fit failed, you have to put a comment the line\nmodel_ccm_long$fit &lt;- NA\nmodel_ccm_long$fit[model_ccm_long$Crossmap == \"X.MY\"] &lt;- predict(ccm_fit_X)\nmodel_ccm_long$fit[model_ccm_long$Crossmap == \"Y.MX\"] &lt;- predict(ccm_fit_Y)\n\nggplot(model_ccm_long, aes(x = L, y = Rho, color = Crossmap)) +\n  geom_point(size = 1) +\n  geom_line(aes(x = L, y = fit)) +\n  scale_color_manual(values = c(\"X.MY\" = \"blue\", \"Y.MX\" = \"red\"),\n                     aesthetics = c(\"colour\", \"fill\"),\n                     breaks = c(\"X.MY\", \"Y.MX\"),\n                     labels =  c(\"Y xmap X\", \"X xmap Y\")) +\n  ylab(TeX(\"$\\\\rho$\")) +\n  theme_classic() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n8.2.4.1 Causal network\nIn order to construct the causal network, we start by extracting the \\(\\rho\\)-values from the fitted models. The broom package makes this a lot easier.\n\nlibrary(broom)\n\nrho_X_to_Y &lt;- broom::tidy(ccm_fit_X) |&gt; \n  filter(term == \"r\") |&gt; \n  select(estimate) |&gt; \n  as.numeric()\n\n# If the ccm_fit_Y model did not converge, replace this by zero\n# rho_Y_to_X &lt;- 0\nrho_Y_to_X &lt;- broom::tidy(ccm_fit_Y) |&gt; \n  filter(term == \"r\") |&gt; \n  select(estimate) |&gt; \n  as.numeric()\n\n# Construct a data frame that defines the network\nrho_links &lt;- data.frame(from = c(\"X\", \"Y\"),\n                        to = c(\"Y\", \"X\"),\n                        rho = c(rho_X_to_Y, rho_Y_to_X))\n\nNow we can use the extracted parameter estimates and use them to create a network plot of the assessed causal couplings.\n\n\nlibrary(igraph)\nlibrary(ggraph)\n\nrho_graph &lt;- rho_links %&gt;% \n  graph_from_data_frame()\n\nggraph(rho_graph, layout = \"fr\") +\n  geom_edge_arc(aes(label = round(rho, 2)),\n                color = \"darkgrey\",\n                arrow = arrow(length = unit(4, 'mm')), \n                end_cap = circle(3, 'mm')) +\n  geom_edge_arc(aes(width = rho),\n                alpha = .25, \n                end_cap = circle(3, 'mm')) +\n  geom_node_point(aes(color = name), size = 5) + \n  geom_node_text(aes(label = name),  repel = TRUE,\n                 nudge_x = 0.05, nudge_y = 0.05) +\n  scale_color_manual(values = c(\"X\" = \"blue\", \"Y\" = \"red\"),\n                     aesthetics = c(\"colour\", \"fill\")) +\n  theme_graph() +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Convergent Cross Mapping</span>"
    ]
  },
  {
    "objectID": "ccm.html#example-using-empirical-data-hands-on-exercise-4",
    "href": "ccm.html#example-using-empirical-data-hands-on-exercise-4",
    "title": "8  Convergent Cross Mapping",
    "section": "8.3 Example using empirical data (hands-on exercise 4)",
    "text": "8.3 Example using empirical data (hands-on exercise 4)\nThis section uses partial and down sampled data from a pilot experiment, where pairs of participants performed various tasks including speaking and moving together. The data are from an unpublished study by Fusaroli, Tylén & Mønster.\n\n\nlibrary(readr)\nphys &lt;- read_csv(\"https://tildeweb.au.dk/~au78495/physiology.csv\",\n                 show_col_types = FALSE)\n\n# Make z-scores\nphys$Resp1 &lt;- scale(phys$Resp1)\nphys$HR1 &lt;- scale(phys$HR1)\nphys$Resp2 &lt;- scale(phys$Resp2)\nphys$HR2 &lt;- scale(phys$HR2)\n\n\n# Produce a long form of the data with a Subject variable\nphys_long &lt;- phys %&gt;% \n  pivot_longer(cols = c(Resp1, Resp2),\n               names_to = \"Subject\",\n               names_pattern = \"Resp([0-9]+)\",\n               values_to = \"Resp\") %&gt;% \n  pivot_longer(cols = c(HR1, HR2),\n               names_to = \"S2\",\n               names_pattern = \"HR([0-9]+)\",\n               values_to = \"HR\") %&gt;% \n  filter(Subject == S2) %&gt;% \n  select(-S2)\n\nHere is a plot of part of the data.\n\nggplot(phys_long, aes(x = min, y = Resp)) +\n  geom_line(colour = \"blue\", na.rm = TRUE) +\n  geom_line(aes(x = min, y = HR), colour = \"red\", na.rm = TRUE) +\n  xlim(c(min(phys$min), 10)) +\n  ylab(\"Signal (z-score)\") +\n  theme_classic() +\n  facet_wrap(.~ Subject)\n\n\n\n\n\n\n\n\n\n8.3.1 Estimate embedding parameters\nTry to find a single value of the time delay and embedding dimension that can be used for all four time series, i.e., respiration and heart rate for subject 1 and subject 2.\n\n# library() # You may need to load some packages here\n\n# Option 1: Use optimizeParam from the crqa package\nparam &lt;- list(method = \"crqa\", metric = \"euclidean\",\n              maxlag = 20, radiusspan = 100, normalize = 0, rescale = 0,\n              mindiagline = 2, minvertline = 2, tw = 0, whiteline = FALSE,\n              recpt = FALSE , side = \"both\", datatype = \"continuous\",\n              fnnpercent = 10, typeami = \"mindip\")\n\n# You need to put in some time series here\n\n# embed_param &lt;- crqa::optimizeParam(TS1, TS2,\n#                      par = param)\n\n# Option 2: Use mutualInformation and estimateEmbeddingDim from nonlinearTseries\n\n# nonlinearTseries::mutualInformation() # Fill in the blanks\n# nonlinearTseries::estimateEmbeddingDim() # Fill in the blanks\n\n# Option 3: Use mutual and false.nearest from tseriesChaos\n\n# Get the variable names, but drop the time variables.\nvar_names &lt;- colnames(phys)[3:6]\n\n# Calculate AMI for each variable and collect the results in a data frame\nAMI &lt;- data.frame()\nfor (v in var_names) {\n  v_ami &lt;- tseriesChaos::mutual(phys[, v], lag.max = 20, plot = FALSE)\n  AMI &lt;- rbind(AMI,\n               as.vector(v_ami) %&gt;% \n                 as.data.frame() %&gt;% \n                 mutate(var = v))\n}\n\n# Set column names and add time delay\ncolnames(AMI) &lt;- c(\"ami\", \"var\")\nAMI &lt;- AMI %&gt;% \n  group_by(var) %&gt;% \n  mutate(delay = row_number()) %&gt;% \n  ungroup()\n\n# Plot the results, so the delay can be estimated\nggplot(AMI, aes(x = delay, y = ami)) +\n  geom_line() +\n  geom_point() +\n  ylab(\"AMI\") +\n  theme_classic() +\n  facet_wrap(.~ var, ncol = 2)\nggsave(\"Plots/physiology_ami.pdf\",\n       width = 16, height = 10, units = \"cm\")\n\n#\n# Set the delay here\n#\ndelay &lt;- NA # Enter value\n\n# Calculate FNN for each variable and collect the results in a data frame\nFNN &lt;- data.frame()\nfor (v in var_names) {\n  v_fnn &lt;- tseriesChaos::false.nearest(series = phys[, v], \n                   m = 15, d = delay, t = 1, eps = 1)\n  FNN &lt;- rbind(FNN,\n               as.vector(v_fnn[\"total\", ]) %&gt;% \n                 as.data.frame() %&gt;% \n                 mutate(var = v))\n}\n\n# Set column names and add time delay\ncolnames(FNN) &lt;- c(\"fnn\", \"var\")\nFNN &lt;- FNN %&gt;% \n  group_by(var) %&gt;% \n  mutate(m = row_number()) %&gt;% \n  ungroup()\n\n# Plot the results, so the embedding dimension can be estimated\nggplot(FNN, aes(x = m, y = fnn)) +\n  geom_line() +\n  geom_point() +\n  ylab(\"FNN\") +\n  theme_classic() +\n  facet_wrap(.~ var, ncol = 2)\nggsave(\"Plots/physiology_fnn.pdf\",\n       width = 16, height = 10, units = \"cm\")\n\n#\n# Set embedding dimension\n#\ndimen &lt;- NA # Enter value\n\n\n\n8.3.2 Convergent cross mapping\nLook at all pairwise cross mappings\n\n# Generate all pairwise combinations of variables\nvariables &lt;- c(\"Resp1\", \"HR1\", \"Resp2\", \"HR2\")\ncombinations &lt;- combn(variables, 2)\n# Get the row numbers and add them as the first column as required by CCM\nidx &lt;- as.numeric(rownames(phys))\nccm_data &lt;- cbind(time = idx, phys)\n  \n# Create an empty list to hold results\nccm_output_list &lt;- list()\nfor (pair in 1:ncol(combinations)) {\n  ccm_out &lt;- CCM(dataFrame = ccm_data, E = dimen, tau = -delay, Tp = 0,\n                 columns = combinations[1, pair],\n                 target = combinations[2, pair],\n                 libSizes = \"20 450 10\", sample = 30,\n                 showPlot = FALSE)\n  \n  # Rename columns to valid R names\n  colnames(ccm_out) &lt;- make.names(colnames(ccm_out))\n  ccm_output_list[[pair]] &lt;- ccm_out\n}\n\n# Merge all the data frames in the list to a single data frame\nccm_all_pairs &lt;- Reduce(function(x,y) merge(x = x, y = y, by = \"LibSize\"), \n       ccm_output_list)\n\nCreate a long form version of the data for easier plotting.\n\nccm_results &lt;- ccm_all_pairs %&gt;%\n  rename(L = LibSize) %&gt;% \n  pivot_longer(cols = -L,\n               names_to = \"Crossmap\",\n               values_to = \"Rho\")\n\nMake our own plot.\n\nggplot(ccm_results, aes(x = L, y = Rho)) +\n  geom_point(size = 1, colour = \"grey\") +\n  ylab(TeX(\"$\\\\rho$\")) +\n  theme_classic() +\n  theme(legend.position = \"top\") +\n  facet_wrap(.~ Crossmap, ncol = 3)\n\nIt should produce something similar to the plot below.\n\n\n\n\n\nFit all cross-mapped values to \\(\\rho(L)\\) and gather the r-values (\\(\\rho_\\infty\\)) in a data frame.\n\nccm_results$fit &lt;- NA\n\n# To catch errors, put nls() call inside try()\nmodel_list &lt;- list()\nfor (xmap in unique(ccm_results$Crossmap)) {\n  model_fit &lt;- try(\n    nls(Rho ~ a * exp(-g * L) + r,\n                     data = ccm_results %&gt;% filter(Crossmap == xmap),\n                     start = list(a = -0.55, g = 0.05, r = 0.5)),\n    TRUE\n  )\n  if(class(model_fit) == \"try-error\") {\n    next\n  } else {\n    model_list[xmap] &lt;- model_fit\n  }\n}\n\n# Now calculate model predictions and add them to ccm_results\nfor (xmap in names(model_list)) {\n  ccm_results$fit[ccm_results$Crossmap == xmap] &lt;- model_list[[xmap]]$predict()\n}\n\nPlot the fitted results\n\nggplot(ccm_results, aes(x = L, y = Rho)) +\n  geom_point(size = 1, colour = \"grey\") +\n  geom_line(aes(x = L, y = fit)) +\n  ylab(TeX(\"$\\\\rho$\")) +\n  theme_classic() +\n  theme(legend.position = \"top\") +\n  facet_wrap(.~ Crossmap, ncol = 3)\n\nIf all went well, you should get a plot like the one shown below.\n\n\n\n\n\nExtract the fitted rho values and construct a data frame that defines the causal network.\n\n# Construct a data frame that defines the network\nrho_links &lt;- data.frame(from = character(),\n                        to = character(),\n                        rho = numeric())\n\n# Extract the variables involved in the cross mapping\n# and the fitted rho at infinite library size.\n# Note: causality goes opposite to cross map direction\n# i.e., high rho X:Y means causal link from Y to X.\n\ncounter &lt;- 0\nrow_list &lt;- list()\nfor (xmap in names(model_list)) {\n  counter &lt;- counter + 1\n  from_to &lt;- strsplit(xmap, \"\\\\.\")[[1]]\n  from_value &lt;- from_to[2]\n  to_value &lt;- from_to[1]\n  rho_value &lt;- as.numeric(model_list[[xmap]]$getPars()[\"r\"])\n  row_list[[counter]] &lt;-  data.frame(from = from_value,\n                                     to = to_value,\n                                     rho = rho_value)\n}\n\nrho_links &lt;- do.call(rbind, row_list)\n\n\nrho_graph &lt;- rho_links |&gt; \n  graph_from_data_frame()\n\nggraph(rho_graph, layout = \"fr\") +\n  geom_edge_arc(aes(label = round(rho, 2)),\n                color = \"darkgrey\",\n                arrow = arrow(length = unit(4, 'mm')), \n                end_cap = circle(3, 'mm')) +\n  geom_edge_arc(aes(width = rho),\n                alpha = .25, \n                end_cap = circle(3, 'mm')) +\n  geom_node_point(aes(color = name), size = 5) + \n  geom_node_text(aes(label = name),  repel = TRUE,\n                 nudge_x = 0.05, nudge_y = 0.05) +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\nThe resulting network graph might look something like this, but note that the layout can change a lot from time to time, so yours may look quite different, even with the same values.\n\n\n\n\n\nNote that some variables, such as speaking and movement of the two subjects have been left out of the data for simplicity. Could these variables explain some of the observed high couplings between the two subjects?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Convergent Cross Mapping</span>"
    ]
  },
  {
    "objectID": "ccm.html#further-reading-and-useful-links",
    "href": "ccm.html#further-reading-and-useful-links",
    "title": "8  Convergent Cross Mapping",
    "section": "Further reading and useful links",
    "text": "Further reading and useful links\nR package: rEDM\nMATLAB code: xmap\nG. Sugihara, R. May, H. Ye, C.-h. Hsieh, E. Deyle, M. Fogarty, S. Munch. (2012). Detecting causality in complex ecosystems Science, 338 (6106), 496-500, DOI:10.1126/science.1227079\nMønster, D., Fusaroli, R., Tylén, K., Roepstorff, A., & Sherson, J. F. (2017). Causal inference from noisy time-series data—Testing the Convergent Cross-Mapping algorithm in the presence of noise and external influence. Future Generation Computer Systems, 73, 52-62. DOI: 10.1016/j.future.2016.12.009",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Convergent Cross Mapping</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Coco, Moreno I., Dan Mønster, Giuseppe Leonardi, Rick Dale, and\nSebastian Wallot. 2021. “Unidimensional and Multidimensional\nMethods for Recurrence Quantification Analysis with\nCrqa.” The R Journal 13 (1): 145–63. https://doi.org/10.32614/RJ-2021-062.\n\n\nMarwan, Norbert, M. Carmen Romano, Marco Thiel, and Jürgen Kurths. 2007.\n“Recurrence Plots for the Analysis of Complex Systems.”\nPhysics Reports 438 (56): 237–329. https://doi.org/10.1016/j.physrep.2006.11.001.",
    "crumbs": [
      "References"
    ]
  }
]